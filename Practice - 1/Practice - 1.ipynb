{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "path = os.getcwd()\n",
    "df_test = pd.read_csv(path + '/test.csv')\n",
    "df_train = pd.read_csv(path + '/train.csv')\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Data Overview </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dimension\n",
    "print('Dimension of Test Data ', df_test.shape)\n",
    "print('Dimension of Train Data', df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data type\n",
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing value\n",
    "def missing_data(data):\n",
    "    df_train_missing = pd.DataFrame(data.isna().sum())\n",
    "    df_train_missing.reset_index(level = 0, inplace = True)\n",
    "    df_train_missing.columns = ['Column Name', 'Total Missing Values']\n",
    "    df_train_missing = df_train_missing.sort_values(by = 'Total Missing Values', ascending = False)\n",
    "    return df_train_missing\n",
    "\n",
    "missing_data(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing data df_train\n",
    "\n",
    "missing_data(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate categorical and integer\n",
    "df_train_cat = df_train.select_dtypes(include = ['object'])\n",
    "df_train_numeric = df_train.select_dtypes(include = ['int64', 'float64']).dropna() #drop the no to show distribution graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical value\n",
    "for column in df_train_cat.columns[1:]: \n",
    "    sns.set()\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.countplot(x=column, data=df_train_cat) \n",
    "    fig.set_size_inches(5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numeric distribution\n",
    "\n",
    "for column in df_train_numeric.columns:\n",
    "    sns.set()\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.distplot(df_train_numeric[column])\n",
    "    fig.set_size_inches(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation matrix\n",
    "sns.heatmap(df_train.corr(), linewidths=.5)\n",
    "fig.set_size_inches(15, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Key findings = Applicant Income and Co-applicant Income is highly correlated with the amount of loan borrowed </p> \n",
    "<b> Recommendation </b> <li> drop the Applicant and Co-applicant Income column and generate new ratio of loan and income to a new column </li> <li> Predict <i> Loan Amount </i> based on <i> Applicant and Co-applicant Income </i> with KNN </li> \n",
    "<li> drop other columns with na </li>\n",
    "<li> encode all categorical data </li>\n",
    "<li> upsample loan status 'zero' </li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Feature Engineering </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict loan amount\n",
    "df_loan_predict = df_train[['ApplicantIncome', 'LoanAmount']]\n",
    "df_loan_predict_test = df_loan_predict[df_loan_predict['LoanAmount'].isnull()].drop(['LoanAmount'], axis = 1)\n",
    "df_loan_predict_train = df_loan_predict[df_loan_predict['LoanAmount'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loan_predict_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "x = df_loan_predict_train.drop(['LoanAmount'], axis = 1)\n",
    "y = df_loan_predict_train['LoanAmount']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state  =42)\n",
    "\n",
    "knn = KNeighborsRegressor()\n",
    "knn.fit(x_train, y_train)\n",
    "pred_knn = knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.score(x_test, pred_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill missing value with KNN\n",
    "prediction_data = knn.predict(df_loan_predict_test)\n",
    "predicted_loan = pd.DataFrame({'LoanAmount': prediction_data})\n",
    "\n",
    "df_loan_predict_test = df_loan_predict_test.reset_index(drop = True)\n",
    "df_loan_predict_test['LoanAmount'] = predicted_loan\n",
    "\n",
    "df_loan_predict_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge missing value to the df_train\n",
    "df_train_test = df_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append table\n",
    "df_train_test_null = df_train_test[df_loan_predict['LoanAmount'].isnull()].reset_index(drop = True)\n",
    "df_train_test_notnull =  df_train_test[df_train_test['LoanAmount'].notnull()].reset_index(drop = True) #need to reset index so it can be appended\n",
    "df_train_test_null = df_train_test_null.drop(['LoanAmount'], axis = 1)\n",
    "df_train_test_null['LoanAmount'] = df_loan_predict_test['LoanAmount']\n",
    "df_train_test_null\n",
    "df_loan_clean = df_train_test_notnull.append(df_train_test_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loan_clean.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop row with na\n",
    "df_naan_clean = df_loan_clean.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop applicant and coapplicant income and generate loan to income column\n",
    "df_naan_clean['LoanToIncome'] = df_naan_clean['LoanAmount']/df_naan_clean['ApplicantIncome'] * 100\n",
    "df_test['LoanToIncome'] = df_test['LoanAmount']/df_test['ApplicantIncome'] * 100\n",
    "df_clean = df_naan_clean.drop(['Loan_ID'], axis = 1)\n",
    "df_test = df_test.drop(['Loan_ID'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_naan = df_test.dropna()\n",
    "df_test_naan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode categorical data\n",
    "df_clean.select_dtypes(include = ['object']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode categorical data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "#dependent\n",
    "le.fit(df_clean['Dependents'])\n",
    "df_clean['Dependents'] = le.transform(df_clean['Dependents'])\n",
    "df_test_naan['Dependents'] = le.transform(df_test_naan['Dependents'])\n",
    "\n",
    "#Education\n",
    "le.fit(df_clean['Education'])\n",
    "df_clean['Education'] = le.transform(df_clean['Education'])\n",
    "df_test_naan['Education'] = le.transform(df_test_naan['Education'])\n",
    "\n",
    "#Gender\n",
    "le.fit(df_clean['Gender'])\n",
    "df_clean['Gender'] = le.transform(df_clean['Gender'])\n",
    "df_test_naan['Gender'] = le.transform(df_test_naan['Gender'])\n",
    "\n",
    "#Married\n",
    "le.fit(df_clean['Married'])\n",
    "df_clean['Married'] = le.transform(df_clean['Married'])\n",
    "df_test_naan['Married'] = le.transform(df_test_naan['Married'])\n",
    "\n",
    "#Property_Area\n",
    "le.fit(df_clean['Property_Area'])\n",
    "df_clean['Property_Area'] = le.transform(df_clean['Property_Area'])\n",
    "df_test_naan['Property_Area'] = le.transform(df_test_naan['Property_Area'])\n",
    "\n",
    "#Self_Employed\n",
    "le.fit(df_clean['Self_Employed'])\n",
    "df_clean['Self_Employed'] = le.transform(df_clean['Self_Employed'])\n",
    "df_test_naan['Self_Employed'] = le.transform(df_test_naan['Self_Employed'])\n",
    "\n",
    "#Loan Status\n",
    "le.fit(df_clean['Loan_Status'])\n",
    "df_clean['Loan_Status'] = le.transform(df_clean['Loan_Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_naan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upsample\n",
    "df_clean.Loan_Status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upsampling 0 loan\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "minority = df_clean[df_clean.Loan_Status == 0]\n",
    "majority = df_clean[df_clean.Loan_Status == 1]\n",
    "df_minority = resample(minority, replace = True, n_samples = 341, random_state = 303)\n",
    "df_upsampled = pd.concat([majority, df_minority])\n",
    "df_upsampled.Loan_Status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#minmax\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mm = MinMaxScaler()\n",
    "mm.fit(df_upsampled[['LoanToIncome', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount']])\n",
    "\n",
    "df_upsampled[['LoanToIncome', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount']] = mm.transform(df_upsampled[['LoanToIncome', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_upsampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test data can't be transformed\n",
    "\n",
    "#df_test_naan[['LoanToIncome', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount']] = mm.transform(df_test_naan[['LoanToIncome', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_naan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model building\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "x = df_upsampled.drop(['Loan_Status'], axis = 1)\n",
    "y = df_upsampled['Loan_Status']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "#model function\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train, y_train)\n",
    "pred_logreg = logreg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svc\n",
    "clf = svm.SVC()\n",
    "clf.fit(x_train, y_train)\n",
    "pred_clf = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest\n",
    "rfc = RandomForestClassifier(n_estimators = 200)\n",
    "rfc.fit(x_train, y_train)\n",
    "pred_rfc = rfc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neural networks\n",
    "mlpc = MLPClassifier(hidden_layer_sizes = (6, 6, 6), max_iter = 500)\n",
    "mlpc.fit(x_train, y_train)\n",
    "pred_mlpc = mlpc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perceptorn\n",
    "prec = Perceptron()\n",
    "prec.fit(x_train, y_train)\n",
    "pred_prec = prec.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SGDClassifier\n",
    "sgdc = SGDClassifier()\n",
    "sgdc.fit(x_train, y_train)\n",
    "pred_sgdc = sgdc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train, y_train)\n",
    "pred_knn = knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes\n",
    "gauss = GaussianNB()\n",
    "gauss.fit(x_train, y_train)\n",
    "pred_gauss = gauss.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision tree\n",
    "dstree = DecisionTreeClassifier()\n",
    "dstree.fit(x_train, y_train)\n",
    "pred_dstree = dstree.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model evaluation\n",
    "\n",
    "#accuracy score\n",
    "rfc_score = accuracy_score(y_test, pred_rfc)\n",
    "mlpc_score = accuracy_score(y_test, pred_mlpc)\n",
    "logreg_score = accuracy_score(y_test, pred_logreg)\n",
    "prec_score = accuracy_score(y_test, pred_prec)\n",
    "sgdc_score = accuracy_score(y_test, pred_sgdc)\n",
    "knn_score = accuracy_score(y_test, pred_knn)\n",
    "gauss_score = accuracy_score(y_test, pred_gauss)\n",
    "dstree_score = accuracy_score(y_test, pred_dstree)\n",
    "\n",
    "modelResult = pd.DataFrame({\n",
    "    'Model': ['Random Forest', 'Neural Networks', 'Logistic Regression', \n",
    "             'Preceptorn', 'SGDC', 'KNN', 'Naive Bayes', 'Decisiton Tree'],\n",
    "    'Score': [rfc_score, mlpc_score, logreg_score, prec_score, sgdc_score, knn_score, gauss_score, dstree_score]\n",
    "    \n",
    "})\n",
    "\n",
    "modelResult.sort_values(by = 'Score', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> <b> <i> Random Forest </i> and <i> Decision Tree </i> appear to be top models </b> </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(\"Random Forest {}\".format(confusion_matrix(y_test, pred_rfc, labels = [1, 0])))\n",
    "\n",
    "print(\"Decision Tree {}\".format(confusion_matrix(y_test, pred_dstree, labels = [1, 0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Hyperparameter Tuning </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter tuning\n",
    "\n",
    "print(\"Random Forest Parameter \\n\")\n",
    "print(rfc.get_params())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
